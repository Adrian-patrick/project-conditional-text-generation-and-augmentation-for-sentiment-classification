{
  "best_global_step": 9447,
  "best_metric": 0.4783950746059418,
  "best_model_checkpoint": "C:/Users/adria/OneDrive/Desktop/CODING/jupyter/models/goemotion/gpt2\\checkpoint-9447",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 9447,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.031756113051762465,
      "grad_norm": 2.4033024311065674,
      "learning_rate": 1.1555889480300245e-05,
      "loss": 1.7069,
      "step": 100
    },
    {
      "epoch": 0.06351222610352493,
      "grad_norm": 2.475897789001465,
      "learning_rate": 1.1432376339211102e-05,
      "loss": 0.5455,
      "step": 200
    },
    {
      "epoch": 0.09526833915528739,
      "grad_norm": 2.0576868057250977,
      "learning_rate": 1.1308863198121958e-05,
      "loss": 0.535,
      "step": 300
    },
    {
      "epoch": 0.12702445220704986,
      "grad_norm": 1.7278456687927246,
      "learning_rate": 1.1185350057032815e-05,
      "loss": 0.5045,
      "step": 400
    },
    {
      "epoch": 0.15878056525881232,
      "grad_norm": 1.8083515167236328,
      "learning_rate": 1.1061836915943672e-05,
      "loss": 0.541,
      "step": 500
    },
    {
      "epoch": 0.19053667831057478,
      "grad_norm": 4.416914939880371,
      "learning_rate": 1.0938323774854528e-05,
      "loss": 0.5266,
      "step": 600
    },
    {
      "epoch": 0.22229279136233726,
      "grad_norm": 1.3981518745422363,
      "learning_rate": 1.0814810633765385e-05,
      "loss": 0.5141,
      "step": 700
    },
    {
      "epoch": 0.2540489044140997,
      "grad_norm": 1.4579823017120361,
      "learning_rate": 1.0691297492676242e-05,
      "loss": 0.5125,
      "step": 800
    },
    {
      "epoch": 0.2858050174658622,
      "grad_norm": 1.282536506652832,
      "learning_rate": 1.0567784351587098e-05,
      "loss": 0.5032,
      "step": 900
    },
    {
      "epoch": 0.31756113051762463,
      "grad_norm": 1.0754286050796509,
      "learning_rate": 1.0444271210497955e-05,
      "loss": 0.5138,
      "step": 1000
    },
    {
      "epoch": 0.3493172435693871,
      "grad_norm": 1.151463508605957,
      "learning_rate": 1.0320758069408812e-05,
      "loss": 0.5039,
      "step": 1100
    },
    {
      "epoch": 0.38107335662114955,
      "grad_norm": 1.245693325996399,
      "learning_rate": 1.0197244928319668e-05,
      "loss": 0.527,
      "step": 1200
    },
    {
      "epoch": 0.412829469672912,
      "grad_norm": 1.3910491466522217,
      "learning_rate": 1.0073731787230525e-05,
      "loss": 0.5111,
      "step": 1300
    },
    {
      "epoch": 0.4445855827246745,
      "grad_norm": 1.0098363161087036,
      "learning_rate": 9.950218646141382e-06,
      "loss": 0.5097,
      "step": 1400
    },
    {
      "epoch": 0.476341695776437,
      "grad_norm": 0.9942005276679993,
      "learning_rate": 9.826705505052238e-06,
      "loss": 0.4823,
      "step": 1500
    },
    {
      "epoch": 0.5080978088281994,
      "grad_norm": 1.220827341079712,
      "learning_rate": 9.703192363963095e-06,
      "loss": 0.4963,
      "step": 1600
    },
    {
      "epoch": 0.5398539218799618,
      "grad_norm": 0.9753653407096863,
      "learning_rate": 9.579679222873952e-06,
      "loss": 0.5058,
      "step": 1700
    },
    {
      "epoch": 0.5716100349317244,
      "grad_norm": 1.0785017013549805,
      "learning_rate": 9.456166081784809e-06,
      "loss": 0.4982,
      "step": 1800
    },
    {
      "epoch": 0.6033661479834869,
      "grad_norm": 0.9929840564727783,
      "learning_rate": 9.332652940695665e-06,
      "loss": 0.5012,
      "step": 1900
    },
    {
      "epoch": 0.6351222610352493,
      "grad_norm": 0.8212261199951172,
      "learning_rate": 9.209139799606524e-06,
      "loss": 0.4997,
      "step": 2000
    },
    {
      "epoch": 0.6668783740870118,
      "grad_norm": 0.8928619623184204,
      "learning_rate": 9.085626658517379e-06,
      "loss": 0.503,
      "step": 2100
    },
    {
      "epoch": 0.6986344871387742,
      "grad_norm": 1.0138481855392456,
      "learning_rate": 8.962113517428237e-06,
      "loss": 0.4974,
      "step": 2200
    },
    {
      "epoch": 0.7303906001905367,
      "grad_norm": 0.7879301309585571,
      "learning_rate": 8.838600376339092e-06,
      "loss": 0.4907,
      "step": 2300
    },
    {
      "epoch": 0.7621467132422991,
      "grad_norm": 0.9352152943611145,
      "learning_rate": 8.71508723524995e-06,
      "loss": 0.4926,
      "step": 2400
    },
    {
      "epoch": 0.7939028262940616,
      "grad_norm": 0.8526210188865662,
      "learning_rate": 8.591574094160805e-06,
      "loss": 0.4969,
      "step": 2500
    },
    {
      "epoch": 0.825658939345824,
      "grad_norm": 1.0210574865341187,
      "learning_rate": 8.468060953071664e-06,
      "loss": 0.496,
      "step": 2600
    },
    {
      "epoch": 0.8574150523975865,
      "grad_norm": 0.8771277070045471,
      "learning_rate": 8.344547811982519e-06,
      "loss": 0.4993,
      "step": 2700
    },
    {
      "epoch": 0.889171165449349,
      "grad_norm": 1.016864538192749,
      "learning_rate": 8.221034670893377e-06,
      "loss": 0.5165,
      "step": 2800
    },
    {
      "epoch": 0.9209272785011114,
      "grad_norm": 1.050350308418274,
      "learning_rate": 8.097521529804234e-06,
      "loss": 0.5025,
      "step": 2900
    },
    {
      "epoch": 0.952683391552874,
      "grad_norm": 0.9102299213409424,
      "learning_rate": 7.97400838871509e-06,
      "loss": 0.4977,
      "step": 3000
    },
    {
      "epoch": 0.9844395046046364,
      "grad_norm": 0.9190610647201538,
      "learning_rate": 7.850495247625947e-06,
      "loss": 0.4839,
      "step": 3100
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.4834921956062317,
      "eval_runtime": 30.0961,
      "eval_samples_per_second": 209.263,
      "eval_steps_per_second": 26.183,
      "step": 3149
    },
    {
      "epoch": 1.0161956176563989,
      "grad_norm": 0.8640710115432739,
      "learning_rate": 7.726982106536804e-06,
      "loss": 0.5035,
      "step": 3200
    },
    {
      "epoch": 1.0479517307081614,
      "grad_norm": 0.7563034296035767,
      "learning_rate": 7.6034689654476596e-06,
      "loss": 0.4732,
      "step": 3300
    },
    {
      "epoch": 1.0797078437599237,
      "grad_norm": 1.0139063596725464,
      "learning_rate": 7.479955824358517e-06,
      "loss": 0.4925,
      "step": 3400
    },
    {
      "epoch": 1.1114639568116862,
      "grad_norm": 0.9422619342803955,
      "learning_rate": 7.356442683269374e-06,
      "loss": 0.4739,
      "step": 3500
    },
    {
      "epoch": 1.1432200698634487,
      "grad_norm": 0.8469682335853577,
      "learning_rate": 7.23292954218023e-06,
      "loss": 0.4855,
      "step": 3600
    },
    {
      "epoch": 1.1749761829152112,
      "grad_norm": 0.849651038646698,
      "learning_rate": 7.109416401091087e-06,
      "loss": 0.4793,
      "step": 3700
    },
    {
      "epoch": 1.2067322959669737,
      "grad_norm": 0.8874895572662354,
      "learning_rate": 6.985903260001943e-06,
      "loss": 0.4655,
      "step": 3800
    },
    {
      "epoch": 1.238488409018736,
      "grad_norm": 0.9203395843505859,
      "learning_rate": 6.8623901189128005e-06,
      "loss": 0.4709,
      "step": 3900
    },
    {
      "epoch": 1.2702445220704985,
      "grad_norm": 0.9051322340965271,
      "learning_rate": 6.738876977823656e-06,
      "loss": 0.4893,
      "step": 4000
    },
    {
      "epoch": 1.302000635122261,
      "grad_norm": 1.0316821336746216,
      "learning_rate": 6.615363836734514e-06,
      "loss": 0.4841,
      "step": 4100
    },
    {
      "epoch": 1.3337567481740236,
      "grad_norm": 1.2449713945388794,
      "learning_rate": 6.49185069564537e-06,
      "loss": 0.4722,
      "step": 4200
    },
    {
      "epoch": 1.365512861225786,
      "grad_norm": 1.0254489183425903,
      "learning_rate": 6.368337554556227e-06,
      "loss": 0.4902,
      "step": 4300
    },
    {
      "epoch": 1.3972689742775484,
      "grad_norm": 0.9388138651847839,
      "learning_rate": 6.244824413467084e-06,
      "loss": 0.4743,
      "step": 4400
    },
    {
      "epoch": 1.4290250873293109,
      "grad_norm": 0.9433385729789734,
      "learning_rate": 6.1213112723779406e-06,
      "loss": 0.4871,
      "step": 4500
    },
    {
      "epoch": 1.4607812003810734,
      "grad_norm": 0.9501587748527527,
      "learning_rate": 5.997798131288797e-06,
      "loss": 0.4572,
      "step": 4600
    },
    {
      "epoch": 1.4925373134328357,
      "grad_norm": 0.9023894667625427,
      "learning_rate": 5.874284990199655e-06,
      "loss": 0.4943,
      "step": 4700
    },
    {
      "epoch": 1.5242934264845984,
      "grad_norm": 0.8595755696296692,
      "learning_rate": 5.750771849110511e-06,
      "loss": 0.488,
      "step": 4800
    },
    {
      "epoch": 1.5560495395363607,
      "grad_norm": 0.8239001631736755,
      "learning_rate": 5.627258708021367e-06,
      "loss": 0.491,
      "step": 4900
    },
    {
      "epoch": 1.5878056525881232,
      "grad_norm": 1.015668272972107,
      "learning_rate": 5.503745566932224e-06,
      "loss": 0.4801,
      "step": 5000
    },
    {
      "epoch": 1.6195617656398857,
      "grad_norm": 0.8874708414077759,
      "learning_rate": 5.380232425843081e-06,
      "loss": 0.4803,
      "step": 5100
    },
    {
      "epoch": 1.651317878691648,
      "grad_norm": 0.8935452699661255,
      "learning_rate": 5.256719284753937e-06,
      "loss": 0.4571,
      "step": 5200
    },
    {
      "epoch": 1.6830739917434108,
      "grad_norm": 1.1351507902145386,
      "learning_rate": 5.133206143664794e-06,
      "loss": 0.4803,
      "step": 5300
    },
    {
      "epoch": 1.714830104795173,
      "grad_norm": 0.8494358062744141,
      "learning_rate": 5.009693002575651e-06,
      "loss": 0.4631,
      "step": 5400
    },
    {
      "epoch": 1.7465862178469356,
      "grad_norm": 0.9581401348114014,
      "learning_rate": 4.886179861486507e-06,
      "loss": 0.4845,
      "step": 5500
    },
    {
      "epoch": 1.778342330898698,
      "grad_norm": 1.1058106422424316,
      "learning_rate": 4.762666720397365e-06,
      "loss": 0.4754,
      "step": 5600
    },
    {
      "epoch": 1.8100984439504604,
      "grad_norm": 0.7773562073707581,
      "learning_rate": 4.6391535793082216e-06,
      "loss": 0.4821,
      "step": 5700
    },
    {
      "epoch": 1.841854557002223,
      "grad_norm": 0.8533564805984497,
      "learning_rate": 4.515640438219078e-06,
      "loss": 0.4817,
      "step": 5800
    },
    {
      "epoch": 1.8736106700539854,
      "grad_norm": 0.9416613578796387,
      "learning_rate": 4.392127297129935e-06,
      "loss": 0.4754,
      "step": 5900
    },
    {
      "epoch": 1.9053667831057477,
      "grad_norm": 0.9838992357254028,
      "learning_rate": 4.268614156040792e-06,
      "loss": 0.4709,
      "step": 6000
    },
    {
      "epoch": 1.9371228961575104,
      "grad_norm": 0.9160923957824707,
      "learning_rate": 4.145101014951648e-06,
      "loss": 0.486,
      "step": 6100
    },
    {
      "epoch": 1.9688790092092727,
      "grad_norm": 0.9258414506912231,
      "learning_rate": 4.021587873862505e-06,
      "loss": 0.4781,
      "step": 6200
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.4789038896560669,
      "eval_runtime": 29.9126,
      "eval_samples_per_second": 210.547,
      "eval_steps_per_second": 26.343,
      "step": 6298
    },
    {
      "epoch": 2.0006351222610355,
      "grad_norm": 1.2166451215744019,
      "learning_rate": 3.898074732773362e-06,
      "loss": 0.4753,
      "step": 6300
    },
    {
      "epoch": 2.0323912353127978,
      "grad_norm": 0.921396791934967,
      "learning_rate": 3.7745615916842183e-06,
      "loss": 0.4606,
      "step": 6400
    },
    {
      "epoch": 2.06414734836456,
      "grad_norm": 0.9741783142089844,
      "learning_rate": 3.6510484505950754e-06,
      "loss": 0.464,
      "step": 6500
    },
    {
      "epoch": 2.0959034614163228,
      "grad_norm": 0.9400794506072998,
      "learning_rate": 3.527535309505932e-06,
      "loss": 0.4485,
      "step": 6600
    },
    {
      "epoch": 2.127659574468085,
      "grad_norm": 0.9742003679275513,
      "learning_rate": 3.404022168416789e-06,
      "loss": 0.4741,
      "step": 6700
    },
    {
      "epoch": 2.1594156875198474,
      "grad_norm": 0.855424165725708,
      "learning_rate": 3.2805090273276455e-06,
      "loss": 0.4675,
      "step": 6800
    },
    {
      "epoch": 2.19117180057161,
      "grad_norm": 1.0120912790298462,
      "learning_rate": 3.156995886238502e-06,
      "loss": 0.4766,
      "step": 6900
    },
    {
      "epoch": 2.2229279136233724,
      "grad_norm": 0.8458948135375977,
      "learning_rate": 3.033482745149359e-06,
      "loss": 0.4562,
      "step": 7000
    },
    {
      "epoch": 2.254684026675135,
      "grad_norm": 1.0476244688034058,
      "learning_rate": 2.9099696040602155e-06,
      "loss": 0.4836,
      "step": 7100
    },
    {
      "epoch": 2.2864401397268974,
      "grad_norm": 0.9570817947387695,
      "learning_rate": 2.786456462971072e-06,
      "loss": 0.4614,
      "step": 7200
    },
    {
      "epoch": 2.3181962527786597,
      "grad_norm": 0.9601189494132996,
      "learning_rate": 2.662943321881929e-06,
      "loss": 0.4665,
      "step": 7300
    },
    {
      "epoch": 2.3499523658304224,
      "grad_norm": 0.9749385118484497,
      "learning_rate": 2.5394301807927856e-06,
      "loss": 0.4599,
      "step": 7400
    },
    {
      "epoch": 2.3817084788821847,
      "grad_norm": 0.9141350388526917,
      "learning_rate": 2.4159170397036427e-06,
      "loss": 0.4648,
      "step": 7500
    },
    {
      "epoch": 2.4134645919339475,
      "grad_norm": 0.9533681273460388,
      "learning_rate": 2.2924038986144993e-06,
      "loss": 0.4705,
      "step": 7600
    },
    {
      "epoch": 2.4452207049857098,
      "grad_norm": 0.7922517657279968,
      "learning_rate": 2.168890757525356e-06,
      "loss": 0.4652,
      "step": 7700
    },
    {
      "epoch": 2.476976818037472,
      "grad_norm": 0.9334740042686462,
      "learning_rate": 2.0453776164362127e-06,
      "loss": 0.4739,
      "step": 7800
    },
    {
      "epoch": 2.508732931089235,
      "grad_norm": 1.092235803604126,
      "learning_rate": 1.9218644753470694e-06,
      "loss": 0.4742,
      "step": 7900
    },
    {
      "epoch": 2.540489044140997,
      "grad_norm": 0.9375492334365845,
      "learning_rate": 1.7983513342579263e-06,
      "loss": 0.4701,
      "step": 8000
    },
    {
      "epoch": 2.57224515719276,
      "grad_norm": 0.8790628910064697,
      "learning_rate": 1.6748381931687827e-06,
      "loss": 0.4788,
      "step": 8100
    },
    {
      "epoch": 2.604001270244522,
      "grad_norm": 1.0378692150115967,
      "learning_rate": 1.5513250520796394e-06,
      "loss": 0.4663,
      "step": 8200
    },
    {
      "epoch": 2.6357573832962844,
      "grad_norm": 1.1668353080749512,
      "learning_rate": 1.4278119109904963e-06,
      "loss": 0.4675,
      "step": 8300
    },
    {
      "epoch": 2.667513496348047,
      "grad_norm": 0.8595438599586487,
      "learning_rate": 1.304298769901353e-06,
      "loss": 0.4674,
      "step": 8400
    },
    {
      "epoch": 2.6992696093998094,
      "grad_norm": 0.908831775188446,
      "learning_rate": 1.1807856288122097e-06,
      "loss": 0.4787,
      "step": 8500
    },
    {
      "epoch": 2.731025722451572,
      "grad_norm": 0.8372371792793274,
      "learning_rate": 1.0572724877230664e-06,
      "loss": 0.4657,
      "step": 8600
    },
    {
      "epoch": 2.7627818355033344,
      "grad_norm": 1.0397313833236694,
      "learning_rate": 9.337593466339231e-07,
      "loss": 0.4707,
      "step": 8700
    },
    {
      "epoch": 2.7945379485550967,
      "grad_norm": 1.1148438453674316,
      "learning_rate": 8.102462055447799e-07,
      "loss": 0.4855,
      "step": 8800
    },
    {
      "epoch": 2.8262940616068595,
      "grad_norm": 0.9671167135238647,
      "learning_rate": 6.867330644556366e-07,
      "loss": 0.4779,
      "step": 8900
    },
    {
      "epoch": 2.8580501746586218,
      "grad_norm": 1.11738920211792,
      "learning_rate": 5.632199233664933e-07,
      "loss": 0.4534,
      "step": 9000
    },
    {
      "epoch": 2.8898062877103845,
      "grad_norm": 0.970287561416626,
      "learning_rate": 4.3970678227735007e-07,
      "loss": 0.475,
      "step": 9100
    },
    {
      "epoch": 2.921562400762147,
      "grad_norm": 1.1192703247070312,
      "learning_rate": 3.161936411882068e-07,
      "loss": 0.4634,
      "step": 9200
    },
    {
      "epoch": 2.953318513813909,
      "grad_norm": 1.1160616874694824,
      "learning_rate": 1.9268050009906348e-07,
      "loss": 0.4712,
      "step": 9300
    },
    {
      "epoch": 2.9850746268656714,
      "grad_norm": 0.7742776870727539,
      "learning_rate": 6.916735900992023e-08,
      "loss": 0.4771,
      "step": 9400
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.4783950746059418,
      "eval_runtime": 29.9061,
      "eval_samples_per_second": 210.593,
      "eval_steps_per_second": 26.349,
      "step": 9447
    }
  ],
  "logging_steps": 100,
  "max_steps": 9447,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4936067776512000.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
